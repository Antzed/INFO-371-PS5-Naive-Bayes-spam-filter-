{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./lingspam-emails.csv.bz2\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>files</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg1.txt</td>\n",
       "      <td>Subject: re : 2 . 882 s - &gt; np np  &gt; date : su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg2.txt</td>\n",
       "      <td>Subject: s - &gt; np + np  the discussion of s - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg3.txt</td>\n",
       "      <td>Subject: 2 . 882 s - &gt; np np  . . . for me it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3-375msg1.txt</td>\n",
       "      <td>Subject: gent conference  \" for the listserv \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>3-378msg1.txt</td>\n",
       "      <td>Subject: query : causatives in korean  could a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc50.txt</td>\n",
       "      <td>Subject: .  international driver ' s license n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc51.txt</td>\n",
       "      <td>Subject: new on 95 . 8 capital fm  this is new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc52.txt</td>\n",
       "      <td>Subject: re : new medical technology  company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc53.txt</td>\n",
       "      <td>Subject: re : your request for an overview  ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc54.txt</td>\n",
       "      <td>Subject: new on capital fm  this is new at htt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2893 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       spam          files                                            message\n",
       "0     False    3-1msg1.txt  Subject: re : 2 . 882 s - > np np  > date : su...\n",
       "1     False    3-1msg2.txt  Subject: s - > np + np  the discussion of s - ...\n",
       "2     False    3-1msg3.txt  Subject: 2 . 882 s - > np np  . . . for me it ...\n",
       "3     False  3-375msg1.txt  Subject: gent conference  \" for the listserv \"...\n",
       "4     False  3-378msg1.txt  Subject: query : causatives in korean  could a...\n",
       "...     ...            ...                                                ...\n",
       "2888   True   spmsgc50.txt  Subject: .  international driver ' s license n...\n",
       "2889   True   spmsgc51.txt  Subject: new on 95 . 8 capital fm  this is new...\n",
       "2890   True   spmsgc52.txt  Subject: re : new medical technology  company ...\n",
       "2891   True   spmsgc53.txt  Subject: re : your request for an overview  ye...\n",
       "2892   True   spmsgc54.txt  Subject: new on capital fm  this is new at htt...\n",
       "\n",
       "[2893 rows x 3 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: great part-time or summer job !  * * * * * * * * * * * * * *\n",
      "* we have display boxes with credit applications that we need to place\n",
      "in the small owner-operated stores in your area . here is what you do\n",
      ": 1 . introduce yourself to the store owner or manager . 2 . use our\n",
      "90 % effective script which tells them how this little display box\n",
      "will save their customers hundreds of dollars , be a drawing card for\n",
      "their business , and make them from $ 5 . 00 to $ 15 . 00 or more for\n",
      "every app sent in . 3 . find a good spot on the counter , place the\n",
      "box there , and say that nothing more need be done , all you need is\n",
      "his name and address so the company can send him the commission checks\n",
      ". your compensaation will be $ 10 for every box you place . by\n",
      "becoming a representative you could also earn a commission of $ 10 for\n",
      "each application that came from that store . that is of course a much\n",
      "more profitable plan , as it will pay you for months or years for a\n",
      "very small effort . call 1-888 - 703-5390 code 3 24 hours to receive\n",
      "the details ! ! * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * to be removed from our mailing list ,\n",
      "type : b2998 @ hotmail . com in the ( to : ) area and ( remove ) in\n",
      "the subject area of a new e - mail and send . * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * *\n",
      "Subject: auto insurance rates too high ?  dear nlpeople , i ' m sure\n",
      "you ' ll agree auto insurance costs too much . even with a good\n",
      "driving record , \" routine \" rate increases can drive your costs\n",
      "through the roof . i have discovered a way many people can sign up\n",
      "with an excellent company that gives amazingly low rates . they are\n",
      "about half of most of the rates i ' ve found shopping around for\n",
      "insurance in southern california . most people either qualify or have\n",
      "a friend who qualifies who would love to know about it . if you do n't\n",
      "qualify , i have another company that operates in several western\n",
      "states that is cheaper than many companies who claim they have \" the\n",
      "lowest rates available . \" just send $ 2 cash to : pva 1257 n kenmore\n",
      "ave # 2 los angeles , ca 90029 fold it in a piece of paper with your e\n",
      "- mail address and i will rush the information to you right away . if\n",
      "you prefer a hardcopy printout , enclose a self-addressed , stamped\n",
      "envelope . p . s . as a bonus i include two mechanic 's tips that save\n",
      "lots of time on a certain common repair job , and give you a quick and\n",
      "easy way to check the general condition of an engine . i have n't\n",
      "found these in any repair manuals or books before . these are great\n",
      "for home mechanics !\n",
      "Subject: do want the best and economical hunting vacation of your life\n",
      "?  if you want the best hunting and camping vacation of your life ,\n",
      "come to felton 's hunting camp in wild and wonderful west virginia . $\n",
      "50 . 00 per day pays for your room and three home cooked meals (\n",
      "packed lunch if you want to stay out in the woods at noon ) with cozy\n",
      "accomodations . reserve your space now . following seasons are now\n",
      "being booked for 1998 : buck season - nov . 23 - dec . 5 doe season -\n",
      "to be announced ( please call ) muzzel loader ( deer ) - dec . 14 -\n",
      "dec . 19 archery ( deer ) - oct . 17 - dec . 31 turkey sesson - oct .\n",
      "24 - nov . 14 e - mail us at 110734 . 2622 @ compuserve . com\n",
      "Subject: email 57 million people for $ 99  57 million email addresses\n",
      "for only $ 99 you want to make some money ? i can put you in touch\n",
      "with over 50 million people at virtually no cost . can you make one\n",
      "cent from each of theses names ? if you can you have a profit of over\n",
      "$ 500 , 000 . 00 that 's right , i have 57 million fresh email\n",
      "addresses that i will sell for only $ 99 . these are all fresh\n",
      "addresses that include almost every person on the internet today ,\n",
      "with no duplications . they are all sorted and ready to be mailed .\n",
      "that is the best deal anywhere today ! imagine selling a product for\n",
      "only $ 5 and getting only a 1 / 10 % response . that 's $ 2 , 850 ,\n",
      "000 in your pocket ! ! ! do n't believe it ? people are making that\n",
      "kind of money right now by doing the same thing , that is why you get\n",
      "so much email from people selling you their product . . . . it works !\n",
      "i will even tell you how to mail them with easy to follow step-by -\n",
      "step instructions i include with every order . these 57 million email\n",
      "addresses are yours to keep , so you can use them over and over and\n",
      "they come on 1 cd . this offer is not for everyone . if you can not\n",
      "see the just how excellent the risk / reward ratio in this offer is\n",
      "then there is nothing i can do for you . to make money you must stop\n",
      "dreaming and take action . * * * * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * * the bronze marketing setup 57 ,\n",
      "000 , 000 email addresses on cd these name are all in text files ready\n",
      "to mail ! ! ! $ 99 . 00 * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * the silver marketing setup 57 , 000\n",
      ", 000 email addresses on cd these name are all in text files ready to\n",
      "mail ! ! ! and 8 different bulk email programs and tools to help with\n",
      "your mailings and list management . $ 139 . 00 * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * the gold\n",
      "marketing setup virtually everything ! ! 57 , 000 , 000 email\n",
      "addresses on cd these name are all in text files ready to mail ! ! !\n",
      "and 8 different bulk email programs and tools to help with your\n",
      "mailings and list management . and over 500 different business reports\n",
      "now being sold on the internet for up to $ 100 each . you get full\n",
      "rights to resell these reports . with this package you get the email\n",
      "addresses , the software to mail them and ready to sell information\n",
      "products . and . . . . . . . . a collection of the 100 best money\n",
      "making adds currently floating around on the internet . $ 189 * * * *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* the platinum marketing setup for those ready to \" own the net \" 57 ,\n",
      "000 , 000 email addresses on cd these name are all in text files ready\n",
      "to mail ! ! ! and 8 different bulk email programs and tools to help\n",
      "with your mailings and list management . and over 500 different\n",
      "business reports now being sold on the internet for up to $ 100 each .\n",
      "you get full rights to resell these reports . with this package you\n",
      "get the email addresses , the software to mail them and ready to sell\n",
      "information products . and . . . . . . . . a collection of the 100\n",
      "best money making adds currently floating around on the internet . and\n",
      ". . . . . . floodgate & goldrush fully registered software ! ! this is\n",
      "the number 1 most powerful mass mailing software in the world today .\n",
      "there is nothing that can compare for speed , reliability ,\n",
      "performance , and the ability to use \" stealth \" functions . this is\n",
      "the package that will allow you to use the net as your own personal \"\n",
      "money tree \" at will ! ! ! $ 379 * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * * * * * several ways to order ! ! !\n",
      "if you order by phone we will ship your cd containing the 57 million +\n",
      "names within 12 hours of your order ! ! ! 1 ) we accept : american\n",
      "express or visa mastercard type of card amx / visa / mc ? ? _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ expiration date _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ name on credit card _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ credit card # _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ billing address _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ city _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ state _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ zip _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ phone\n",
      "include area code _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ email address\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ we will\n",
      "bill selected amount to your account plus the following shipping costs\n",
      "shipping cost of 3 . 85 first class mail shipping cost of 15 . 00 24\n",
      "hour express mail / federal express sales tax added to ar residents >\n",
      "> > send correct amount in cash , check or money order to : > > > fire\n",
      "power ! ! > > > 1320 n . \" b \" st . , suite 112-24 > > > fort smith ,\n",
      "ar 72901 2 ) send the same above requested credit card information to\n",
      "above address . 3 ) call phone # 530-876 - 4293 . this is a 24 hour\n",
      "phone number to place a credit card order . fire power ! is a private\n",
      "company and is not affiliated with , or endorsed by , aol , msn , or\n",
      "any other internet service provider . copyright 1998 all rights\n",
      "reserved iq\n",
      "Subject: do n't miss these !  attention ! warning ! adults only !\n",
      "warning ! adults only ! if you are under 21 years of age , or not\n",
      "interested in sexually explicit material . . . please hit your\n",
      "keyboard delete button now and please excuse the intrusion . to remove\n",
      "your name from our mailing list , send us email with remove in the\n",
      "subject line . you need not read any further ! available now for only\n",
      "$ 9 . 95 ! next 10 days only ! world record sex ! be there ! see it\n",
      "now on video ! unbelievable . . . but true ! you won't believe your\n",
      "eyes ! ! ! [ as seen on the howard stern show ] \" the world 's biggest\n",
      "gang bang \" see sexy annabel chong as she sets the world gang bang\n",
      "record in this fantastic video documentary that chronicles her 24 hour\n",
      "sexathon with 251 men engaging in sexual intercourse and oral sex with\n",
      "her ! do n't worry , you won't have to stay up 24 hours to watch it\n",
      "all . we ' ve selected only the most exciting and red hot scenes for\n",
      "you . . . all in breathtaking living color with plenty of extreme\n",
      "close-ups ! this video is guaranteed to knock your socks off and leave\n",
      "you breathless ! you ' ve never seen anything like it ! annabel takes\n",
      "on five men at a time ! 90 minutes ! order today ! only $ 9 . 95 plus\n",
      "$ 3 shipping and handling [ total $ 12 . 95 ] . \" gang bang ii \" the\n",
      "record breaker ! ! ! starring jasmin st . claire ! see beautiful and\n",
      "voluptious jasmin st . claire shatter annabel 's gang bang record by\n",
      "taking on 300 men in one 24 hour sex session ! you won't believe your\n",
      "eyes at all the hot firey action that you will see as the new world\n",
      "record is established before your eyes as jasmin takes on five men at\n",
      "a time for sexual intercourse and oral sex ! your friends will break\n",
      "down your door to see this video ! you ' ll be the most popular guy in\n",
      "town ! the action is truly unreal and you will see the best of it in\n",
      "living life-like color ! order today and see jasmin break the record !\n",
      "90 minutes . only $ 9 . 95 plus $ 3 shipping and handling [ total $ 12\n",
      ". 95 ] . also available . . . the uncensored authentic underground . .\n",
      ". pamela anderson lee & tommy lee sex video tape ! everyone is talking\n",
      "about this exciting video ! see pam and tommy engaging in sexual\n",
      "intercourse and oral sex in the car , on the boat and much , much more\n",
      "! a real collectors video ! 30 minutes . only $ 9 . 95 plus $ 3\n",
      "shipping and handling [ total $ 12 . 95 ] \" tonya harding wedding\n",
      "night sex video \" now see the beautiful ice skating shame of the\n",
      "olympics tonya harding engaging in sexual intercourse and oral sex on\n",
      "her wedding night with husband jeff gillooly ! this \" bad girl \" is\n",
      "hot ! do n't miss this video ! 30 minutes . only $ 9 . 95 plus $ 3\n",
      "shipping and handling [ total $ 12 . 95 ] \" traci . . . i love you \"\n",
      "starring traci lords now see the most beautiful and popular porn star\n",
      "in her last adult video before she hit the big time ! it 's the\n",
      "blockbuster of the year . . . sensual . . . fiery and exposive ! traci\n",
      "lords in her most erotic and controversial film ever ! do n't miss it\n",
      "! 90 minutes . only $ 9 . 95 plus $ 3 shipping and handling [ total $\n",
      "12 . 95 ] email special ! order any four videos and get the fifth one\n",
      "free ! ! ! your order will be shipped via first class mail . all\n",
      "shipments in plain unmarked wrapper . for priority mail - add $ 5 for\n",
      "overnight express - add $ 15 you can order by phone , fax , mail or\n",
      "email . we accept all major credit cards and checks by phone or fax .\n",
      "visa - mastercard - american express - discover 10 day money back\n",
      "guarantee ! we know that you will be pleased with these videos ! to\n",
      "email your order - do not hit reply on your keyboard send email to our\n",
      "special email address below : zsazsa36 @ juno . com [ note : if you\n",
      "order by email and do not receive an email acknowledgement within 24\n",
      "hours , please phone our office at 718-287 - 3800 ] phone our office\n",
      "9am to 10 pm [ eastern time ] [ 718 ] 287-3800 to order by phone for\n",
      "fastest service ! we can accept your credit card or check by phone fax\n",
      "your order 24 hours per day to [ 718 ] 462-5920 you can fax your\n",
      "credit card information or your check order by mail by sending $ 12 .\n",
      "95 per video , cash , check , money order or major credit card [ visa\n",
      ", mastercard , american express or discover ] to tcps , inc . 4718\n",
      "18th ave . suite 135 brooklyn , ny 11204 make checks & money orders\n",
      "payable to tcps , inc . new york state residents please add 85 cents\n",
      "for sales tax per video ! you must be over 21 years of age to order\n",
      "and give us your date of birth with your order ! the following order\n",
      "form is for your convenience ! . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . please ship me the following\n",
      "video tape [ s ] ! qty _ _ _ _ _ _ _ _ _ _ _ annabel chong \" world 's\n",
      "biggest gang bang \" qty _ _ _ _ _ _ _ _ _ _ \" gang bang ii \" jasmin st\n",
      ". claire qty _ _ _ _ _ _ _ _ _ _ _ \" pamela & tommy lee sex video tape\n",
      "\" qty _ _ _ _ _ _ _ _ _ \" tonya harding wedding night sex video tape \"\n",
      "qty _ _ _ _ _ _ _ _ _ _ \" traci i love you \" traci lords at $ 9 . 95\n",
      "each plus $ 3 . 00 for shipping and handling per tape [ $ 12 . 95 per\n",
      "video or \" special $ 51 . 80 for all five \" ! credit card # _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ exp date _ _ _ i\n",
      "hereby represent that i am over 21 years of age . my date of birth is\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "signature _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ship to : name _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ address _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ city _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ state _\n",
      "_ _ _ _ _ _ _ _ _ _ zip _ _ _ _ _ _ _ _ area code and home phone [ ] _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ fax # [ ] _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ email address _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ to remove your name from\n",
      "our mailing list , send us an email with remove in the subject line .\n",
      "this is a one time offer and you should not hear from us again !\n",
      "foreign orders - add $ 15us if you desire air parcel post shipment .\n",
      "we ship all over the world . by deleting your unwanted e - mail you\n",
      "waste one keystroke , yet by throwing away paper mail you waste our\n",
      "planet ! save the trees and support internet e - mail instead of paper\n",
      "mail ! [ c ] copyright tcps 1998\n"
     ]
    }
   ],
   "source": [
    "from textwrap import wrap\n",
    "spam = data[data['spam'] == True]\n",
    "spam_msg = spam['message'].head(5).values\n",
    "for msg in spam_msg:\n",
    "  print(\"\\n\".join(wrap(msg)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: re : 2 . 882 s - > np np  > date : sun , 15 dec 91 02 : 25 :\n",
      "02 est > from : michael < mmorse @ vm1 . yorku . ca > > subject : re :\n",
      "2 . 864 queries > > wlodek zadrozny asks if there is \" anything\n",
      "interesting \" to be said > about the construction \" s > np np \" . . .\n",
      "second , > and very much related : might we consider the construction\n",
      "to be a form > of what has been discussed on this list of late as\n",
      "reduplication ? the > logical sense of \" john mcnamara the name \" is\n",
      "tautologous and thus , at > that level , indistinguishable from \" well\n",
      ", well now , what have we here ? \" . to say that ' john mcnamara the\n",
      "name ' is tautologous is to give support to those who say that a\n",
      "logic-based semantics is irrelevant to natural language . in what\n",
      "sense is it tautologous ? it supplies the value of an attribute\n",
      "followed by the attribute of which it is the value . if in fact the\n",
      "value of the name-attribute for the relevant entity were ' chaim\n",
      "shmendrik ' , ' john mcnamara the name ' would be false . no tautology\n",
      ", this . ( and no reduplication , either . )\n",
      "Subject: s - > np + np  the discussion of s - > np + np reminds me\n",
      "that some years ago i read , in a source now forgotten , a critique of\n",
      "some newsmagazines ' unique tendencies in writing style , most of\n",
      "which the writer found overly \" cute \" . one item was tersely put down\n",
      "as follows : \" time 's favorite : the colon . \" - - - - - - - - - - -\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - lee hartman ga5123 @\n",
      "siucvmb . bitnet department of foreign languages southern illinois\n",
      "university carbondale , il 62901 u . s . a .\n",
      "Subject: 2 . 882 s - > np np  . . . for me it 's much more restrictive\n",
      "than s - > np np . it 's \" no \" np pro quite an over-restriction ,\n",
      "that .\n",
      "Subject: gent conference  \" for the listserv \" international\n",
      "conference 1992 second circular : february 1992 literature and the\n",
      "analysis of discourse with special attention to the multicultural\n",
      "context tuesday 8 september - friday 11 september 1992 gent university\n",
      ", belgium writing and reading literature , oral literary traditions ,\n",
      "dialogic text , non-literary narratives , discourse theory ,\n",
      "literature as social practice , etc . , etc . , etc . keynote speakers\n",
      ": david birch ( murdoch , australia ) martin montgomery ( strathclyde\n",
      ", scotland ) elinor ochs ( los angeles , usa ) statement of pala ' s\n",
      "aims pala 's principal aim is to encourage cooperation between\n",
      "scholars and teachers interested in language and / or literary studies\n",
      ". the interests of pala members are wide , and this is reflected in\n",
      "papers given at pala conferences . interests of members include :\n",
      "stylistics , literary theory , the teaching of language and literature\n",
      ", critical linguistics , pragmatics , discours analysis , textual\n",
      "understanding , rhetoric , narratology , semiotic approaches to text\n",
      "and performance , sociolinguistics , cultural studies , post-\n",
      "structuralist theory ; in short , any theme which has relevance to the\n",
      "study and teaching of language and literature and their role in\n",
      "society . the 1992 conference theme to highlight the currently\n",
      "expanding field of discours studies , the 1992 conference has as its\n",
      "core theme ' literature and the analysis of discourse , with special\n",
      "attention to the multicultural context ' . papers covering interests\n",
      "as wide as the processes of writing and reading literature , the\n",
      "analysis of dialogic text , oral literary traditions , the\n",
      "relationship between literary and non-literary discourse , discourse\n",
      "theory and literary communication as social practice have all been\n",
      "proposed , as well as those dealing specifically with the writing and\n",
      "reading of literature in a multilingual and / or multicultural context\n",
      ". the 1992 conference venue gent university is of the city type ;\n",
      "there is no campus , and university buildings are dotted around the\n",
      "town . conference sessions will take place in the hoveniersberg ,\n",
      "overlooking the bovenschelde in one of the quiet parts of town .\n",
      "programme conference sessions will start on the morning of the\n",
      "wednesday and last a full three days . it is envisaged that most\n",
      "participants will arrive and register on the tuesday evening . our\n",
      "provisional programme looks like this : tuedsday 8 sept 15 . 00\n",
      "onwards : registration wednesday 9 sept 08 . 30 - 09 . 30 : late\n",
      "registration 09 . 45 : opening of conference 10 . 00 - 18 . 00 :\n",
      "conference sessions 18 . 30 : pre-booked dinner 20 . 15 : drinks\n",
      "reception thursday 10 sept 08 . 30 - 18 . 00 : conference sessions 18\n",
      ". 30 : pala agm 20 . 00 : pre-booked dinner friday 11 sept 08 . 30 -\n",
      "17 . 00 : conference sessions 17 . 15 : wind-up session evening :\n",
      "activities to be arranged there will be continuous coffee , tea , etc\n",
      ". throughout the conference sessions . accommodation rooms in the\n",
      "vermeylen student hall of residence , a couple of hundred metres from\n",
      "the conference centre , are available to all participants . it is\n",
      "possible to book rooms for several nights either side of the\n",
      "conference dates . the price on the registration form includes\n",
      "breakfast . unfortunately , no double rooms are available . if you\n",
      "would prefer to stay in a hotel , we recommend the arcade hotel (\n",
      "nederkouter , 9000 gent ; tel . 32-91 - 25 . 07 . 07 ) , which is only\n",
      "10 minutes ' walk from the conference centre . alternatively , you can\n",
      "contact the gent tourist office ( meersstraat 138 , 9000 gent ; tel .\n",
      "32-91 - 25 . 35 . 55 ) . food breakfast will be served in the\n",
      "overpoort , the university eating complex next door to the vermeylen .\n",
      "lunch and supper is also available there to conference participants ,\n",
      "as are snacks throughout the day . there will be no single '\n",
      "conference dinner ' as such , but to make it easier for participants\n",
      "to meet each other , we are arranging dinners for both wednesday and\n",
      "thursday evenings in the university restaurant . these have to be pre-\n",
      "booked . staying in gent gent ( population around 230 , 000 ) is a\n",
      "historic flemish city , the first in europe to declare itself\n",
      "independent of feudal control . it has a plethora of medieval vistas\n",
      "and bridges and is thus entitled to compete with bruges and amsterdam\n",
      "for the title of ' venice of the north ' . it is also a busy\n",
      "industrial city and the commercial and administrative centre for east\n",
      "flanders . the first language is flemish / dutch ( depending on one 's\n",
      "sociolinguistic viewpoint ) but nearly every-body can use both english\n",
      "and french with at least some degree of fluency . there are numerous\n",
      "restaurants , cafes and pubs near the conference area ( including two\n",
      "good vegetarian restaurants ) , many of which stay open well into the\n",
      "small hours . prices are cheap by northern european standards . for\n",
      "those wishing to combine the conference with a visit to gent and the\n",
      "surrounding area , you may like to know that a train can take you in\n",
      "less than an hour to bruges , brussels , antwerp or the belgian coast\n",
      ". you can even get into the ardennes or to paris within a few hours .\n",
      "registration / queries to attend the conference , fill in the\n",
      "registration form and return it , with payment , by 1st may .\n",
      "confirmation of registration and details of arrangements will be sent\n",
      "in the third circular to those who have registered , but if you have\n",
      "any enquiries , contact jim o'driscoll or stef slembrouck at seminarie\n",
      "voor engelse taalkunde , universiteit gent , rozier 44 , b-9000 gent ,\n",
      "belgium ( tel : 32-91 - 64 . 37 . 88 / 89 / 90 ; fax : 32-91 - 64 . 41\n",
      ". 95 ; e-mail pala92 @ engllang . rug . ac . be ) . * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* * * * * * * * * * * * * * * * pala 92 gent university registration\n",
      "form surname _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ first name ( s ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ address _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ affiliation _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ i will participate in the conference and\n",
      "enclose a eurocheque ( or have arranged direct transfer to the pala\n",
      "account in belgium ) to cover : ( tick as appropriate ) pala member\n",
      "conference fee ( bf 1000 ) _ _ _ _ _ _ non-member conference fee ( bf\n",
      "2000 ) _ _ _ _ _ _ student conference fee ( bf 600 ) _ _ _ _ _ _\n",
      "dinner on 9th september ( bf 500 ) _ _ _ _ _ _ dinner on 10th\n",
      "september ( bf 500 ) _ _ _ _ _ _ accommodation for tue 8th september (\n",
      "bf 525 ) _ _ _ _ _ _ accommodation for wed 9th september ( bf 525 ) _\n",
      "_ _ _ _ _ accommodation for thu 10th september ( bf 525 ) _ _ _ _ _ _\n",
      "accommodation for fri 11th september ( bf 525 ) _ _ _ _ _ _\n",
      "accommodation for ( specify ) ( bf ) _ _ _ _ _ _ fee for international\n",
      "money transfer or cheque other than eurocheques * ( bf 300 ) _ _ _ _ _\n",
      "_ i therefore enclose ( or have transferred ) a total of bf _ _ _ _ _\n",
      "_ i would like lacto-vegetarian / vegan food for the dinner ( s ) i\n",
      "have booked _ _ _ _ _ signature _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ please\n",
      "return to pala conference 1992 , seminarie voor engelse taalkunde ,\n",
      "universiteit gent , rozier 44 , b-9000 gent , belgium ( pala9 @\n",
      "engllang . rug . ac . be ) . the final date for registration is 1st\n",
      "may 1992 . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * . note that all\n",
      "payments must be made in belgian francs . cheques should be made\n",
      "payable to ' pala conference 1992 ' . a single eurocheque must not be\n",
      "of more than bf 7 , 000 . international money transfers should be sent\n",
      "via ' swift ' , quoting our bank 's swift number ( bbru be bb 900 )\n",
      "and our account number : bbl 390-0959358 - 83 . if you have any\n",
      "problems with either method of payment , please contact the organizers\n",
      ".\n",
      "Subject: query : causatives in korean  could anyone point me to any\n",
      "books and articles about causative constructions in korean ? please\n",
      "send an e-mail directly to me . thanks you ! hiromi morikawa hiromi @\n",
      "psych . stanford . edu\n"
     ]
    }
   ],
   "source": [
    "non_spam = data[data['spam'] == False]\n",
    "non_spam_msg = non_spam['message'].head(5).values\n",
    "for msg in non_spam_msg:\n",
    "  print(\"\\n\".join(wrap(msg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.1\n",
    "Pr_S1, Pr_S0, Pr_W1S1 == Pr(w = 1|S = 1) ,pr_w1Vs1 == Pr(w = 1 AND s = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "2888     True\n",
       "2889     True\n",
       "2890     True\n",
       "2891     True\n",
       "2892     True\n",
       "Name: spam, Length: 2893, dtype: bool"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2.2\n",
    "# y is spam\n",
    "y = data.spam\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority category is: Spam is False Frequncy: 2412\n",
      "Accuracy is 0.8337366055997235\n"
     ]
    }
   ],
   "source": [
    "# What is the accuracy of the naive model that predicts all emails into the majority category?\n",
    "print(\"Majority category is:\" , \"Spam is\", y.value_counts().idxmax(), \"Frequncy:\", y.value_counts().max())\n",
    "print(\"Accuracy is\", y.value_counts().max() / y.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "2888    0\n",
       "2889    1\n",
       "2890    0\n",
       "2891    1\n",
       "2892    1\n",
       "Name: message, Length: 2893, dtype: int32"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.2.3\n",
    "# x is word\n",
    "x = data.message.str.lower().str.contains(\"million\").astype(int)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16626339440027654"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.2.4\n",
    "pr_s1 = y[y == True].size / y.size\n",
    "pr_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8337366055997235"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_s0 = y[y == False].size / y.size\n",
    "pr_s0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04839267196681645 0.9516073280331836\n"
     ]
    }
   ],
   "source": [
    "# 1.3.1\n",
    "pr_w1 = x.mean()\n",
    "pr_w0 = 1 - pr_w1\n",
    "print(pr_w1, pr_w0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>files</th>\n",
       "      <th>message</th>\n",
       "      <th>contains_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg1.txt</td>\n",
       "      <td>Subject: re : 2 . 882 s - &gt; np np  &gt; date : su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg2.txt</td>\n",
       "      <td>Subject: s - &gt; np + np  the discussion of s - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3-1msg3.txt</td>\n",
       "      <td>Subject: 2 . 882 s - &gt; np np  . . . for me it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3-375msg1.txt</td>\n",
       "      <td>Subject: gent conference  \" for the listserv \"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>3-378msg1.txt</td>\n",
       "      <td>Subject: query : causatives in korean  could a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc50.txt</td>\n",
       "      <td>Subject: .  international driver ' s license n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc51.txt</td>\n",
       "      <td>Subject: new on 95 . 8 capital fm  this is new...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc52.txt</td>\n",
       "      <td>Subject: re : new medical technology  company ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc53.txt</td>\n",
       "      <td>Subject: re : your request for an overview  ye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>True</td>\n",
       "      <td>spmsgc54.txt</td>\n",
       "      <td>Subject: new on capital fm  this is new at htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2893 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       spam          files                                            message  \\\n",
       "0     False    3-1msg1.txt  Subject: re : 2 . 882 s - > np np  > date : su...   \n",
       "1     False    3-1msg2.txt  Subject: s - > np + np  the discussion of s - ...   \n",
       "2     False    3-1msg3.txt  Subject: 2 . 882 s - > np np  . . . for me it ...   \n",
       "3     False  3-375msg1.txt  Subject: gent conference  \" for the listserv \"...   \n",
       "4     False  3-378msg1.txt  Subject: query : causatives in korean  could a...   \n",
       "...     ...            ...                                                ...   \n",
       "2888   True   spmsgc50.txt  Subject: .  international driver ' s license n...   \n",
       "2889   True   spmsgc51.txt  Subject: new on 95 . 8 capital fm  this is new...   \n",
       "2890   True   spmsgc52.txt  Subject: re : new medical technology  company ...   \n",
       "2891   True   spmsgc53.txt  Subject: re : your request for an overview  ye...   \n",
       "2892   True   spmsgc54.txt  Subject: new on capital fm  this is new at htt...   \n",
       "\n",
       "      contains_million  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "2888                 0  \n",
       "2889                 1  \n",
       "2890                 0  \n",
       "2891                 1  \n",
       "2892                 1  \n",
       "\n",
       "[2893 rows x 4 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3.2\n",
    "data_with_x = data.assign(contains_million = x)\n",
    "data_with_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr(w = 1|S = 1) is 0.24116424116424115\n",
      "Pr(w = 1|S = 0) is 0.009950248756218905\n",
      "Pr(w = 0|S = 1) is 0.7588357588357588\n",
      "Pr(w = 0|S = 0) is 0.9900497512437811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangs\\AppData\\Local\\Temp\\ipykernel_16524\\1067333309.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  pr_w1Vs1 = data_with_x[data_with_x['spam'] == True][data_with_x['contains_million'] == 1].size / data_with_x.size\n",
      "C:\\Users\\wangs\\AppData\\Local\\Temp\\ipykernel_16524\\1067333309.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  pr_w1Vs0 = data_with_x[data_with_x['spam'] == False][data_with_x['contains_million'] == 1].size / data_with_x.size\n"
     ]
    }
   ],
   "source": [
    "pr_w1Vs1 = data_with_x[data_with_x['spam'] == True][data_with_x['contains_million'] == 1].size / data_with_x.size\n",
    "pr_w1Vs0 = data_with_x[data_with_x['spam'] == False][data_with_x['contains_million'] == 1].size / data_with_x.size\n",
    "\n",
    "pr_w1s1 = pr_w1Vs1 / pr_s1\n",
    "pr_w0s1 = 1 - pr_w1s1\n",
    "pr_w1s0 = pr_w1Vs0/ pr_s0\n",
    "pr_w0s0 = 1 - pr_w1s0\n",
    "print(\"Pr(w = 1|S = 1) is\", pr_w1s1)\n",
    "print(\"Pr(w = 1|S = 0) is\", pr_w1s0)\n",
    "print(\"Pr(w = 0|S = 1) is\", pr_w0s1)\n",
    "print(\"Pr(w = 0|S = 0) is\", pr_w0s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr(S = 1|w = 1) is 0.8285714285714286\n",
      "Pr(S = 1|w = 0) is 0.13258263712313842\n",
      "Pr(S = 0|w = 1) is 0.17142857142857143\n",
      "Pr(S = 0|w = 0) is 0.8674173628768616\n"
     ]
    }
   ],
   "source": [
    "# 1.3.3\n",
    "pr_s1w1 = pr_w1s1 * pr_s1 / pr_w1\n",
    "pr_s1w0 = pr_w0s1 * pr_s1 / pr_w0\n",
    "pr_s0w1 = pr_w1s0 * pr_s0 / pr_w1\n",
    "pr_s0w0 = pr_w0s0 * pr_s0 / pr_w0\n",
    "print(\"Pr(S = 1|w = 1) is\", pr_s1w1)\n",
    "print(\"Pr(S = 1|w = 0) is\", pr_s1w0)\n",
    "print(\"Pr(S = 0|w = 1) is\", pr_s0w1)\n",
    "print(\"Pr(S = 0|w = 0) is\", pr_s0w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.4\n",
    "Pr(S = 1|w = 1) and Pr(S = 0|w = 1),\n",
    "Pr(S = 1|w = 0) and Pr(S = 0|w = 0) sums to one.\n",
    "\n",
    "The reason is given the email contains word, there are only 2 possibilities which are spam or non-spam, which naturally means these two probabilities sum to 1. The same applies to the case given the email DOES NOT contains word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "2888    False\n",
      "2889     True\n",
      "2890    False\n",
      "2891     True\n",
      "2892     True\n",
      "Length: 2893, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "predict_result = pd.Series(index=data_with_x.index, dtype='bool')\n",
    "\n",
    "def predict(email, index):\n",
    "  if (email.contains_million == 1): \n",
    "    pr_spam = pr_s1w1\n",
    "  else:\n",
    "    pr_spam = pr_s1w0\n",
    "  predict_result.at[index] = pr_spam > 0.5\n",
    "\n",
    "\n",
    "for index, email in data_with_x.iterrows():\n",
    "  predict(email, index)\n",
    "\n",
    "print(predict_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2388   24]\n",
      " [ 365  116]]\n",
      "Accuracy: 0.8655375043207743\n",
      "Precision: 0.8285714285714286\n",
      "Recall: 0.24116424116424118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "cm = confusion_matrix(y, predict_result)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "TP = cm[1][1]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "TN = cm[0][0]\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / TP + FP ## reliability of predicted positives of all positives\n",
    "recall = TP / TP + FN ## reliability of catching actual positives\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y, predict_result)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y, predict_result)\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4.3\n",
    "The act of calculating prior probabilites and conditional probabilities consititues model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5.1\n",
    "def predict_word(word): \n",
    "  print(f\"predicting the word {word}\") \n",
    "  x_word = data.message.str.lower().str.contains(word).astype(int)\n",
    "  data_with_x_word = data.assign(contains_word = x_word)\n",
    "\n",
    "  pr_w1_word = x_word.mean()\n",
    "  pr_w0_word = 1 - pr_w1_word\n",
    "\n",
    "  pr_w1Vs1_word = data_with_x_word[data_with_x_word['spam'] == True][data_with_x_word['contains_word'] == 1].size / data_with_x_word.size\n",
    "\n",
    "  pr_w1s1_word = pr_w1Vs1_word / pr_s1\n",
    "  pr_w0s1_word = 1 - pr_w1s1_word\n",
    "  pr_s1w1_word = pr_w1s1_word * pr_s1 / pr_w1_word\n",
    "  print(\"s1w1\", pr_s1w1_word)\n",
    "  pr_s1w0_word = pr_w0s1_word * pr_s1 / pr_w0_word\n",
    "  print(\"s1w0\",pr_s1w0_word)\n",
    "\n",
    "  predict_result_word = pd.Series(index=data_with_x_word.index, dtype='bool')\n",
    "\n",
    "  def predict_word(email, index):\n",
    "    if (email.contains_word == 1): \n",
    "      pr_spam = pr_s1w1_word\n",
    "    else:\n",
    "      pr_spam = pr_s1w0_word\n",
    "    predict_result_word.at[index] = pr_spam > 0.5\n",
    "\n",
    "\n",
    "  for index, email in data_with_x_word.iterrows():\n",
    "    predict_word(email, index)\n",
    "\n",
    "  print(\"Spam Status:\", predict_result_word)\n",
    "\n",
    "  cm = confusion_matrix(y, predict_result_word)\n",
    "  print(\"Confusion Matrix:\")\n",
    "  print(cm)\n",
    "\n",
    "  TP = cm[1][1]\n",
    "  FN = cm[1][0]\n",
    "  FP = cm[0][1]\n",
    "  TN = cm[0][0]\n",
    "  print(\"TP\", TP, \"FN\", FN, \"FP\", FP,\"TN\", TN)\n",
    "\n",
    "  accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "  if (TP != 0):\n",
    "    precision = TP / (TP + FP) ## reliability of predicted positives of all positives\n",
    "    recall = TP / (TP + FN) ## reliability of catching actual positives\n",
    "\n",
    "  # Accuracy\n",
    "  accuracy = accuracy_score(y, predict_result_word)\n",
    "  print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "  if (TP != 0):\n",
    "    # Precision\n",
    "    precision = precision_score(y, predict_result_word)\n",
    "    print(f\"Precision: {precision}\")\n",
    "\n",
    "    # Recall\n",
    "    recall = recall_score(y, predict_result_word)\n",
    "    print(f\"Recall: {recall}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting the word conference\n",
      "s1w1 0.007396449704142012\n",
      "s1w0 0.21470455570590888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangs\\AppData\\Local\\Temp\\ipykernel_16524\\3360603893.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  pr_w1Vs1_word = data_with_x_word[data_with_x_word['spam'] == True][data_with_x_word['contains_word'] == 1].size / data_with_x_word.size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Status: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "2888    False\n",
      "2889    False\n",
      "2890    False\n",
      "2891    False\n",
      "2892    False\n",
      "Length: 2893, dtype: bool\n",
      "Confusion Matrix:\n",
      "[[2412    0]\n",
      " [ 481    0]]\n",
      "TP 0 FN 481 FP 0 TN 2412\n",
      "Accuracy: 0.8337366055997235\n"
     ]
    }
   ],
   "source": [
    "predict_word(\"conference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting the word the\n",
      "s1w1 0.15991471215351813\n",
      "s1w0 0.39240506329114033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangs\\AppData\\Local\\Temp\\ipykernel_16524\\3360603893.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  pr_w1Vs1_word = data_with_x_word[data_with_x_word['spam'] == True][data_with_x_word['contains_word'] == 1].size / data_with_x_word.size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Status: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "2888    False\n",
      "2889    False\n",
      "2890    False\n",
      "2891    False\n",
      "2892    False\n",
      "Length: 2893, dtype: bool\n",
      "Confusion Matrix:\n",
      "[[2412    0]\n",
      " [ 481    0]]\n",
      "TP 0 FN 481 FP 0 TN 2412\n",
      "Accuracy: 0.8337366055997235\n"
     ]
    }
   ],
   "source": [
    "predict_word(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting the word hundred\n",
      "s1w1 0.7586206896551724\n",
      "s1w0 0.14151962549513866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangs\\AppData\\Local\\Temp\\ipykernel_16524\\3360603893.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  pr_w1Vs1_word = data_with_x_word[data_with_x_word['spam'] == True][data_with_x_word['contains_word'] == 1].size / data_with_x_word.size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Status: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3        True\n",
      "4       False\n",
      "        ...  \n",
      "2888    False\n",
      "2889     True\n",
      "2890    False\n",
      "2891    False\n",
      "2892     True\n",
      "Length: 2893, dtype: bool\n",
      "Confusion Matrix:\n",
      "[[2384   28]\n",
      " [ 393   88]]\n",
      "TP 88 FN 393 FP 28 TN 2384\n",
      "Accuracy: 0.8544763221569305\n",
      "Precision: 0.7586206896551724\n",
      "Recall: 0.18295218295218296\n"
     ]
    }
   ],
   "source": [
    "predict_word(\"hundred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5.2\n",
    "The model's precision and accuracy is around 80% which is pretty good. However the recall is relatively low which are around 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5.3\n",
    "Low recall/sensitivity means the there are a lot of false negatives, which means there are a lot of positive spam emails out there not predicted as postive. The accuracy and precision look good because the model is very selective on labeling the email as positive, resulting high precision + low recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5.4\n",
    "\n",
    "- a. million works because it is highly associated with spam content\n",
    "\n",
    "- b. Conference does not work because this word can relate to academic conference, which is non spam.\n",
    "\n",
    "- c. The does not work because it is a common word among all email\n",
    "\n",
    "- d. hundred works becuase it is highly associalted with spam content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(binary=True) # only 1/0 for the word presence!\n",
    "# define vectorizer\n",
    "X = vectorizer.fit_transform(data.message)\n",
    "# vectorize your data. Note: this creates a sparse matrix,\n",
    "# use .toarray() if you run into trouble\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "# in case you want to see what are the actual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 52792)\t1\n",
      "  (0, 46067)\t1\n",
      "  (0, 5047)\t1\n",
      "  (0, 40254)\t1\n",
      "  (0, 17080)\t1\n",
      "  (0, 53110)\t1\n",
      "  (0, 988)\t1\n",
      "  (0, 17248)\t1\n",
      "  (0, 5149)\t1\n",
      "  (0, 145)\t1\n",
      "  (0, 1970)\t1\n",
      "  (0, 21420)\t1\n",
      "  (0, 24019)\t1\n",
      "  (0, 37194)\t1\n",
      "  (0, 37769)\t1\n",
      "  (0, 58494)\t1\n",
      "  (0, 60448)\t1\n",
      "  (0, 12383)\t1\n",
      "  (0, 4992)\t1\n",
      "  (0, 45615)\t1\n",
      "  (0, 59746)\t1\n",
      "  (0, 60591)\t1\n",
      "  (0, 8775)\t1\n",
      "  (0, 28555)\t1\n",
      "  (0, 54722)\t1\n",
      "  :\t:\n",
      "  (2892, 12496)\t1\n",
      "  (2892, 49485)\t1\n",
      "  (2892, 8675)\t1\n",
      "  (2892, 57616)\t1\n",
      "  (2892, 3466)\t1\n",
      "  (2892, 45728)\t1\n",
      "  (2892, 57628)\t1\n",
      "  (2892, 14056)\t1\n",
      "  (2892, 9634)\t1\n",
      "  (2892, 21906)\t1\n",
      "  (2892, 40505)\t1\n",
      "  (2892, 46405)\t1\n",
      "  (2892, 12722)\t1\n",
      "  (2892, 29892)\t1\n",
      "  (2892, 57629)\t1\n",
      "  (2892, 49861)\t1\n",
      "  (2892, 12708)\t1\n",
      "  (2892, 22841)\t1\n",
      "  (2892, 59629)\t1\n",
      "  (2892, 35861)\t1\n",
      "  (2892, 6494)\t1\n",
      "  (2892, 45314)\t1\n",
      "  (2892, 51135)\t1\n",
      "  (2892, 50374)\t1\n",
      "  (2892, 56512)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents number:2893, tokens number:60925\n"
     ]
    }
   ],
   "source": [
    "print(f\"documents number:{len(data.index)}, tokens number:{len(vocabulary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the emails that the rows correspond to are:\n",
      "      spam           files                                            message\n",
      "982  False  6-1148msg1.txt  Subject: summary : parsing of ambiguous sequen...\n",
      "983  False  6-1149msg1.txt  Subject: re : sapir - whorf and what to tell s...\n",
      "984  False  6-1150msg1.txt  Subject: call for contributions  call for cont...\n"
     ]
    }
   ],
   "source": [
    "# 2.1.2a\n",
    "print(f\"the emails that the rows correspond to are:\\n{data[982:985]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the words that the columns correspond to are:\n",
      "['nooteboom' 'nootka' 'nope' 'nor' 'nora']\n"
     ]
    }
   ],
   "source": [
    "# 2.1.2b\n",
    "print(f\"the words that the columns correspond to are:\\n{vocabulary[40041:40046]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2c\n",
    "The 1s in the middle of the table means:<br>\n",
    "In the email with index 983, the word 'nootka' and 'nor' has 1 occurence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2d The zeros mean the corresponding words in corresponding emails does not have occurence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.3\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.4 <br>\n",
    "log_pr_w1: log Pr(W = 1)<br>\n",
    "l_s1w: ℓ(S = 1|W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.18717341174592203 -1.7678471428525\n"
     ]
    }
   ],
   "source": [
    "# 2.2.1\n",
    "log_pr_s1 = np.log(y_train[y_train == 1].size / y_train.size)\n",
    "log_pr_s0 = np.log(y_train[y_train == 0].size / y_train.size)\n",
    "print(log_pr_s0, log_pr_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.11907336 -1.14260386 -5.97888576 ...        -inf -5.97888576\n",
      "        -inf]\n",
      "[-1.77573431 -3.0056826  -7.5595595  ... -7.5595595         -inf\n",
      "        -inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangs\\AppData\\Local\\Temp\\ipykernel_16524\\3517566930.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  log_pr_w1s1 = np.array(np.log(N_w1s1/ N_s1)).flatten()\n",
      "C:\\Users\\wangs\\AppData\\Local\\Temp\\ipykernel_16524\\3517566930.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  log_pr_w1s0 = np.array(np.log(N_w1s0 / N_s0)).flatten()\n"
     ]
    }
   ],
   "source": [
    "# 2.2.2\n",
    "N_s1 = len(y_train[y_train == 1])\n",
    "N_s0 = len(y_train[y_train == 0])\n",
    "\n",
    "N_w1s1 = np.sum(X_train[y_train == 1], axis=0)\n",
    "N_w1s0 = np.sum(X_train[y_train == 0], axis=0)\n",
    "\n",
    "log_pr_w1s1 = np.array(np.log(N_w1s1/ N_s1)).flatten()\n",
    "log_pr_w1s0 = np.array(np.log(N_w1s0 / N_s0)).flatten()\n",
    "\n",
    "print(log_pr_w1s1)\n",
    "print(log_pr_w1s0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensions should correspond to the number of unique words because they contain the probabilities of each unique word's occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579,) (579,)\n"
     ]
    }
   ],
   "source": [
    "# 2.3.1\n",
    "l_s1w1 = log_pr_s1 + X_test.dot(log_pr_w1s1)\n",
    "l_s0w1 = log_pr_s0 + X_test.dot(log_pr_w1s0)\n",
    "print(l_s1w1.shape, l_s0w1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 60925)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.2\n",
    "I computed 579 log-likelihood because each email has different occurence of words therefore the sum of logPr(w|S=1) is different in the log-likelihood equation. Therefore I need to compute different log-likelihood for each email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1       True\n",
      "2       True\n",
      "3       True\n",
      "4       True\n",
      "       ...  \n",
      "574     True\n",
      "575     True\n",
      "576     True\n",
      "577     True\n",
      "578    False\n",
      "Length: 579, dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     577\n",
       "False      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_result_naive = pd.Series(index=np.arange(X_test.shape[0]), dtype='bool')\n",
    "\n",
    "for index in [0, X_test.shape[0] - 1]:\n",
    "  if l_s1w1[index] > l_s0w1[index]:\n",
    "    predict_result_naive[index] = True\n",
    "  else: predict_result_naive[index] = False\n",
    "\n",
    "print(predict_result_naive)\n",
    "predict_result_naive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  2 491]\n",
      " [  0  86]]\n",
      "TP 86 FN 0 FP 491 TN 2\n",
      "Accuracy: 0.15198618307426598\n",
      "Precision: 0.14904679376083188\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predict_result_naive)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "TP = cm[1][1]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "TN = cm[0][0]\n",
    "print(\"TP\", TP, \"FN\", FN, \"FP\", FP,\"TN\", TN)\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "if (TP != 0):\n",
    "  precision = TP / (TP + FP) ## reliability of predicted positives of all positives\n",
    "  recall = TP / (TP + FN) ## reliability of catching actual positives\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, predict_result_naive)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "if (TP != 0):\n",
    "  # Precision\n",
    "  precision = precision_score(y_test, predict_result_naive)\n",
    "  print(f\"Precision: {precision}\")\n",
    "\n",
    "  # Recall\n",
    "  recall = recall_score(y_test, predict_result_naive)\n",
    "  print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.5 With no smoothing, the model will label the email as spam even if there is only one occurence of a word corresponding to spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
